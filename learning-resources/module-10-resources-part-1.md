# Module 10: AI Systems Integration - Learning Resources (Part-1)

## 10.1 LLM Fundamentals

### 10.1.1 - AI & LLM Core Concepts

#### Core Concepts
- Foundation models and generative AI
- Transformer architecture fundamentals
- Tokenization and embedding concepts
- Inference optimization techniques
- Fine-tuning approaches and techniques
- Model evaluation and benchmarking

#### Search Terms
- "Large language model fundamentals"
- "Transformer architecture explained"
- "Tokenization and embeddings in LLMs"
- "Inference optimization techniques LLMs"
- "Fine-tuning language models guide"
- "LLM evaluation and benchmarking"

#### Suggested Learning Path
1. **LLM Fundamentals** (1 hour)
   - Understand generative AI concepts
   - Learn transformer architecture
   - Explore attention mechanisms

2. **Tokenization & Embeddings** (1 hour)
   - Implement tokenization methods
   - Create embedding generation
   - Design vector representations

3. **Inference Optimization** (1 hour)
   - Implement quantization techniques
   - Create batching strategies
   - Design latency optimization

4. **Fine-tuning Approaches** (1 hour)
   - Implement parameter-efficient tuning
   - Create dataset preparation
   - Design evaluation methods

5. **Model Evaluation** (1 hour)
   - Implement benchmark suites
   - Create evaluation metrics
   - Design comparative analysis

#### Recommended Resources

**Official Documentation**
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- [OpenAI Documentation](https://platform.openai.com/docs/)
- [TensorFlow Text](https://www.tensorflow.org/text/guide/tokenizers)

**Articles & Tutorials**
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Understanding LLM Tokenization](https://huggingface.co/docs/transformers/tokenizer_summary)
- [Fine-tuning Language Models](https://huggingface.co/docs/transformers/training)

**YouTube Videos**
- [Transformer Architecture Explained (Yannic Kilcher)](https://www.youtube.com/watch?v=TQQlZhbC5ps)
- [LLM Fundamentals (Andrew Ng)](https://www.youtube.com/watch?v=4IuQXKo_nFY)
- [Fine-tuning Tutorial (Hugging Face)](https://www.youtube.com/watch?v=XvSGPZFEjDY)

**GitHub Repositories**
- [transformers](https://github.com/huggingface/transformers)
- [llm-foundry](https://github.com/mosaicml/llm-foundry)
- [lit-llama](https://github.com/Lightning-AI/lit-llama)

---

### 10.1.2 - Prompt Engineering

#### Core Concepts
- Prompt design principles and patterns
- System and user prompts framework
- Chain-of-thought and reasoning techniques
- Zero-shot and few-shot learning
- Prompt templates and variables
- Optimization and testing methods

#### Search Terms
- "Prompt engineering best practices"
- "System and user prompts framework"
- "Chain-of-thought prompting techniques"
- "Zero-shot and few-shot learning examples"
- "Prompt template design patterns"
- "Prompt testing and optimization"

#### Suggested Learning Path
1. **Prompt Fundamentals** (1 hour)
   - Understand prompt components
   - Learn context management
   - Explore role-based prompting

2. **Reasoning Techniques** (1 hour)
   - Implement chain-of-thought
   - Create step-by-step reasoning
   - Design verification prompts

3. **Learning Approaches** (1 hour)
   - Implement zero-shot techniques
   - Create few-shot examples
   - Design in-context learning

4. **Template Systems** (1 hour)
   - Create prompt templates
   - Implement variable substitution
   - Design reusable patterns

5. **Testing Methods** (1 hour)
   - Implement prompt evaluation
   - Create A/B testing
   - Design systematic optimization

#### Recommended Resources

**Official Documentation**
- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [LangChain Prompting](https://python.langchain.com/docs/modules/model_io/prompts/)
- [Anthropic Prompt Design](https://docs.anthropic.com/claude/docs/prompt-design-basics)

**Articles & Tutorials**
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)
- [Few-Shot Prompting Techniques](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)

**YouTube Videos**
- [Prompt Engineering Masterclass (Andrew Ng)](https://www.youtube.com/watch?v=iZT_7aSbicQ)
- [Chain-of-Thought Tutorial (AI Coffee Break)](https://www.youtube.com/watch?v=ibi2iAUQBYQ)
- [Advanced Prompt Engineering (Whiteboard Hub)](https://www.youtube.com/watch?v=ahUU8B0NmHk)

**GitHub Repositories**
- [awesome-prompts](https://github.com/f/awesome-chatgpt-prompts)
- [prompt-engineering-guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [langchain-prompts](https://github.com/hwchase17/langchain/tree/master/langchain/prompts)

---

### 10.1.3 - Local LLMs

#### Core Concepts
- Local deployment of open-source LLMs
- Quantization and optimization techniques
- Inference servers and APIs
- Hardware requirements and scaling
- Model selection and comparison
- Fine-tuning local models

#### Search Terms
- "Local LLM deployment guide"
- "Quantization techniques for LLMs"
- "Inference servers for language models"
- "Hardware requirements for LLM inference"
- "Open source model comparison"
- "Fine-tuning local language models"

#### Suggested Learning Path
1. **Local Deployment** (1 hour)
   - Understand deployment options
   - Learn container-based deployment
   - Explore API server setup

2. **Quantization Techniques** (1 hour)
   - Implement precision reduction
   - Create optimized inference
   - Design memory management

3. **Inference Servers** (1 hour)
   - Configure server deployment
   - Create scaling strategies
   - Design API interfaces

4. **Hardware Optimization** (1 hour)
   - Implement GPU acceleration
   - Create CPU-only solutions
   - Design multi-device inference

5. **Model Management** (1 hour)
   - Implement model selection
   - Create benchmarking tools
   - Design fine-tuning workflows

#### Recommended Resources

**Official Documentation**
- [Ollama](https://ollama.com/docs)
- [LlamaCpp](https://github.com/ggerganov/llama.cpp)
- [vLLM](https://docs.vllm.ai/)

**Articles & Tutorials**
- [Running LLMs Locally](https://itsfoss.com/local-llm-rag-ollama-langchain/)
- [Quantization for LLMs](https://huggingface.co/docs/transformers/main/quantization)
- [Setting up an Inference Server](https://vllm.readthedocs.io/en/latest/serving/setup.html)

**YouTube Videos**
- [Local LLM Deployment (The AI Advantage)](https://www.youtube.com/watch?v=WzCS8z9GqHw)
- [Quantization Tutorial (Yannic Kilcher)](https://www.youtube.com/watch?v=qrLqQ-ihVOU)
- [GPU Acceleration for LLMs (Jeff Heaton)](https://www.youtube.com/watch?v=UlzWqGQJ9_w)

**GitHub Repositories**
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [ollama](https://github.com/ollama/ollama)
- [text-generation-webui](https://github.com/oobabooga/text-generation-webui)

---

### Branch Project 10.1: AI Assistant

#### Core Concepts
- Local LLM deployment and optimization
- Prompt engineering for specific use cases
- Context management and response filtering
- API integration for model interaction
- User interface for assistant interaction
- Performance monitoring and logging

#### Search Terms
- "Building AI assistant with local LLMs"
- "Prompt engineering for personal assistants"
- "Context management for conversations"
- "API integration for language models"
- "UI design for AI assistants"
- "Performance monitoring for LLMs"

#### Suggested Learning Path
1. **LLM Setup** (1-2 hours)
   - Configure local model deployment
   - Implement optimization techniques
   - Design API interface

2. **Prompt System** (1-2 hours)
   - Create system prompts
   - Implement context management
   - Design response filtering

3. **Interaction Design** (1-2 hours)
   - Implement conversation handling
   - Create memory management
   - Design user experience

4. **API Integration** (1-2 hours)
   - Configure model interaction
   - Create response processing
   - Design error handling

5. **Performance Tuning** (1-2 hours)
   - Implement monitoring tools
   - Create optimization methods
   - Design evaluation metrics

#### Recommended Resources

**Official Documentation**
- [Ollama API](https://ollama.com/docs/api)
- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction.html)
- [Gradio](https://gradio.app/docs/)

**Articles & Tutorials**
- [Building an AI Assistant](https://medium.com/@arunpatidar26/rag-chromadb-ollama-python-guide-for-beginners-30857499d0a0)
- [Context Management for LLMs](https://www.pinecone.io/learn/context-window/)
- [UI Design for AI Assistants](https://uxdesign.cc/designing-ai-assistants-how-to-match-natural-language-with-visual-design-cues-a06399d19ccc)

**YouTube Videos**
- [Build Your Own AI Assistant (Code With Ryan)](https://www.youtube.com/watch?v=iFJ1y_3-uT4)
- [LLM-powered Chatbot (Prompt Engineering)](https://www.youtube.com/watch?v=CfmGf93cFHw)
- [Local LLM Assistant (AI Coffee Break)](https://www.youtube.com/watch?v=M2D0wcKyBpM)

**GitHub Repositories**
- [privateGPT](https://github.com/imartinez/privateGPT)
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- [chatbot-ui](https://github.com/mckaywrigley/chatbot-ui)

## 10.2 Vector Databases & RAG

### 10.2.1 - Vector Databases

#### Core Concepts
- Vector embedding fundamentals
- Vector database architectures
- Similarity search techniques
- Indexing strategies and algorithms
- Filtering and metadata integration
- Scaling and performance optimization

#### Search Terms
- "Vector database fundamentals"
- "Embeddings generation for databases"
- "Similarity search techniques"
- "Vector indexing algorithms"
- "Metadata filtering in vector search"
- "Vector database scaling strategies"

#### Suggested Learning Path
1. **Vector Fundamentals** (1 hour)
   - Understand embedding concepts
   - Learn similarity metrics
   - Explore dimensionality properties

2. **Database Selection** (1 hour)
   - Compare vector database options
   - Implement database setup
   - Design data schemas

3. **Indexing Techniques** (1 hour)
   - Implement ANN algorithms
   - Create efficient indexes
   - Design query optimization

4. **Metadata Integration** (1 hour)
   - Implement hybrid search
   - Create filtering strategies
   - Design complex queries

5. **Performance Optimization** (1 hour)
   - Implement database sharding
   - Create caching strategies
   - Design benchmark testing

#### Recommended Resources

**Official Documentation**
- [ChromaDB](https://docs.trychroma.com/)
- [Pinecone](https://docs.pinecone.io/)
- [Weaviate](https://weaviate.io/developers/weaviate)

**Articles & Tutorials**
- [Vector Databases Explained](https://www.pinecone.io/learn/vector-database/)
- [Embeddings and Vector Search](https://www.singlestore.com/blog/vector-search-embeddings-similarity/)
- [Scaling Vector Databases](https://weaviate.io/blog/ann-algorithms-for-vector-search)

**YouTube Videos**
- [Vector Database Fundamentals (DeepLearning.AI)](https://www.youtube.com/watch?v=dN0lsF2cvm4)
- [ChromaDB Tutorial (Prompt Engineering)](https://www.youtube.com/watch?v=XmuNMYvpGf8)
- [Vector Search Algorithms (AI Coffee Break)](https://www.youtube.com/watch?v=nKEni4tJ4KQ)

**GitHub Repositories**
- [chroma](https://github.com/chroma-core/chroma)
- [qdrant](https://github.com/qdrant/qdrant)
- [milvus](https://github.com/milvus-io/milvus)

---

### 10.2.2 - RAG (Retrieval Augmented Generation)

#### Core Concepts
- RAG architecture and implementation
- Document processing and chunking
- Embedding generation strategies
- Retrieval optimization techniques
- Context injection and formatting
- Response synthesis and validation

#### Search Terms
- "RAG architecture implementation Python"
- "Document processing for RAG systems"
- "Embedding generation for retrieval"
- "Retrieval optimization techniques"
- "Context injection patterns LLMs"
- "Response synthesis and validation"

#### Suggested Learning Path
1. **RAG Fundamentals** (1 hour)
   - Understand RAG architecture
   - Learn retrieval approaches
   - Explore generation techniques

2. **Document Processing** (1 hour)
   - Implement text extraction
   - Create chunking strategies
   - Design metadata enhancement

3. **Embedding Strategies** (1 hour)
   - Configure embedding models
   - Create hybrid embeddings
   - Design efficient generation

4. **Retrieval Optimization** (1 hour)
   - Implement query transformation
   - Create re-ranking techniques
   - Design relevance scoring

5. **Context Integration** (1 hour)
   - Implement prompt formatting
   - Create context synthesis
   - Design response generation

#### Recommended Resources

**Official Documentation**
- [LangChain RAG](https://python.langchain.com/docs/use_cases/question_answering/)
- [LlamaIndex](https://docs.llamaindex.ai/)
- [Haystack](https://haystack.deepset.ai/overview/intro)

**Articles & Tutorials**
- [Building RAG Systems](https://github.com/lehoanglong95/rag-all-in-one)
- [RAG with ChromaDB and Ollama](https://medium.com/@arunpatidar26/rag-chromadb-ollama-python-guide-for-beginners-30857499d0a0)
- [RAG and Vector Databases](https://nitya.github.io/generative-ai-for-beginners/15-rag-and-vector-databases/)

**YouTube Videos**
- [RAG from Scratch (DeepLearning.AI)](https://www.youtube.com/watch?v=qD15iJWBIwE)
- [Building RAG Applications (Pinecone)](https://www.youtube.com/watch?v=J_3PZBVu09k)
- [Advanced RAG Techniques (MLOps Community)](https://www.youtube.com/watch?v=bfJCKr78YcU)

**GitHub Repositories**
- [langchain-rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/retrieval_examples.ipynb)
- [llamaindex-rag](https://github.com/jerryjliu/llama_index/tree/main/examples)
- [rag-all-in-one](https://github.com/lehoanglong95/rag-all-in-one)

---

### 10.2.3 - Advanced RAG Techniques

#### Core Concepts
- Multi-query retrieval strategies
- Re-ranking and hybrid search
- Self-verification and fact-checking
- Query routing and orchestration
- Contextual compression techniques
- RAG evaluation and optimization

#### Search Terms
- "Advanced RAG techniques implementation"
- "Multi-query retrieval strategies"
- "Re-ranking for RAG systems"
- "Self-verification in RAG"
- "Query routing and orchestration"
- "RAG evaluation and metrics"

#### Suggested Learning Path
1. **Advanced Retrieval** (1 hour)
   - Implement multi-query generation
   - Create query decomposition
   - Design ensemble methods

2. **Result Enhancement** (1 hour)
   - Implement re-ranking algorithms
   - Create hybrid search techniques
   - Design relevance scoring

3. **Self-verification** (1 hour)
   - Implement fact-checking
   - Create hallucination detection
   - Design confidence scoring

4. **System Orchestration** (1 hour)
   - Implement query routing
   - Create adaptive retrieval
   - Design contextual compression

5. **Evaluation Methods** (1 hour)
   - Implement RAGAS metrics
   - Create benchmark datasets
   - Design optimization strategies

#### Recommended Resources

**Official Documentation**
- [LangChain Advanced RAG](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)
- [LlamaIndex Advanced Features](https://docs.llamaindex.ai/en/stable/optimizing/advanced_retrieval/)
- [RAGAS Documentation](https://github.com/explodinggradients/ragas)

**Articles & Tutorials**
- [Advanced RAG Techniques](https://towardsdatascience.com/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6)
- [RAG Beyond Basics](https://magazine.sebastianraschka.com/p/practical-tips-for-llm-retrieval-augmented)
- [Re-ranking in RAG](https://www.elastic.co/blog/implementing-reranking-for-semantic-search)

**YouTube Videos**
- [Advanced RAG Deep Dive (Prompt Engineering)](https://www.youtube.com/watch?v=GZSQEtfs_lw)
- [Re-ranking Tutorial (Andrew Ng)](https://www.youtube.com/watch?v=gYayCG6Mj-8)
- [Evaluating RAG Systems (LlamaIndex)](https://www.youtube.com/watch?v=bwbkm3CwmGo)

**GitHub Repositories**
- [ragas](https://github.com/explodinggradients/ragas)
- [langchain-advanced-rag](https://github.com/langchain-ai/langchain/tree/master/cookbook)
- [llamaindex-advanced-rag](https://github.com/jerryjliu/llama_index/tree/main/examples/query_engine/advanced_retrieval)

---

### Branch Project 10.2: Document QA System

#### Core Concepts
- RAG implementation for document question-answering
- Multi-format document processing
- Advanced retrieval strategies
- Answer synthesis and citation
- Conversational memory integration
- Evaluation and performance optimization

#### Search Terms
- "Document QA RAG implementation"
- "Multi-format document processing"
- "Advanced retrieval for document QA"
- "Answer synthesis with citations"
- "Conversational memory for QA"
- "RAG evaluation metrics"

#### Suggested Learning Path
1. **System Architecture** (1-2 hours)
   - Design RAG pipeline
   - Create processing workflow
   - Implement component integration

2. **Document Processing** (1-2 hours)
   - Configure multi-format extraction
   - Implement chunking strategies
   - Design metadata enrichment

3. **Retrieval Implementation** (1-2 hours)
   - Create advanced query techniques
   - Implement re-ranking
   - Design relevance optimization

4. **Answer Generation** (1-2 hours)
   - Implement synthesis patterns
   - Create citation mechanisms
   - Design factuality checks

5. **Conversation Design** (1-2 hours)
   - Implement memory integration
   - Create context management
   - Design evaluation metrics

#### Recommended Resources

**Official Documentation**
- [LangChain Document QA](https://python.langchain.com/docs/use_cases/question_answering/)
- [Unstructured.IO](https://unstructured.io/documentation)
- [LlamaIndex RAG](https://docs.llamaindex.ai/en/stable/examples/usecases/doc_qa/)

**Articles & Tutorials**
- [Building a Document QA System](https://towardsdatascience.com/build-a-rag-based-qa-system-using-langchain-and-openai-1b1f28f7f614)
- [Multi-format Document Processing](https://github.com/Unstructured-IO/unstructured)
- [Citations in RAG Systems](https://www.pinecone.io/learn/rag-citation/)

**YouTube Videos**
- [Document QA From Scratch (DeepLearning.AI)](https://www.youtube.com/watch?v=tsa9lumEYNs)
- [Multi-format RAG (Pinecone)](https://www.youtube.com/watch?v=CQWvqfLcfdw)
- [Advanced RAG QA System (Prompt Engineering)](https://www.youtube.com/watch?v=9ISVjh8mdlA)

**GitHub Repositories**
- [privateGPT](https://github.com/imartinez/privateGPT)
- [document-qa-example](https://github.com/langchain-ai/langchain/tree/master/cookbook/solutions/document_qa)
- [llamaindex-rag-qa](https://github.com/jerryjliu/llama_index/tree/main/examples/usecases/doc_qa)
